{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf   #tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist    #28x28 images of hand-written digit 0-9\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()   #Load Image for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show one image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f325ad1748>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[16],cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After normalize our Image look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f321c42080>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0],cmap=plt.cm.binary)  #It is not a color image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the shape of our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Image in training set 60000\n",
      "Number of Target in trainig set 60000\n",
      "Shape of each test image (28, 28)\n",
      "Shape of each target ()\n",
      "Shape of our training set (60000, 28, 28)\n",
      "Shape of our target training set (60000,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of Image in training set\",x_train.shape[0])\n",
    "print (\"Number of Target in trainig set\",y_train.shape[0])\n",
    "print (\"Shape of each test image\",x_train[0].shape)\n",
    "print (\"Shape of each target\",y_train[0].shape)\n",
    "print (\"Shape of our training set\",x_train.shape)\n",
    "print (\"Shape of our target training set\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert target set to categorical vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our sequential model using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.2656 - acc: 0.9223\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.1059 - acc: 0.9666\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.0720 - acc: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f31c5a9390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=3)  #Here we are using only three epochs because the problem is very simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see here training accuracy of our model reach 0.9775 in just 3 epochs because it is very simple model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Our Model on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 902us/step\n",
      "0.09043433521967381 0.9728\n"
     ]
    }
   ],
   "source": [
    "val_loss,val_acc =model.evaluate(x_test,y_test)\n",
    "print(val_loss,val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of our model on testing set is 97.28% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model in Disk for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MNIST.model')   #To Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('MNIST.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let predict for one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f323c1e278>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[7],cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = new_model.predict(np.expand_dims(x_test[7], axis=0))  # Here we used np.expand_dims to make x_test[n] \n",
    "                                                                    #to make 3dims because predict expect batch input, not single\n",
    "                                                                    # input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print (np.argmax(predictions))                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In above image it is 9, and our model is also predicting 9 as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
